{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG6e6Euv9TK7",
        "outputId": "2d204244-5341-4fff-97fc-ce373e84972b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X1c6De8Vq1jY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/imagenette2-160'\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "\n",
        "classes = [d for d in sorted(os.listdir(train_dir)) if os.path.isdir(os.path.join(train_dir, d))]\n",
        "print(f\"Found {len(classes)} classes:\\n\", classes)\n",
        "\n",
        "train_ds_fs = datasets.ImageFolder(train_dir)\n",
        "counts = Counter(train_ds_fs.targets)\n",
        "sample_paths = [p for p, _ in train_ds_fs.samples[:200]]  # inspect first 200 files\n",
        "sizes = Counter()\n",
        "for p in sample_paths:\n",
        "    try:\n",
        "        with Image.open(p) as im:\n",
        "            sizes[im.size] += 1\n",
        "    except Exception as e:\n",
        "        sizes[('err', p)] += 1\n",
        "\n",
        "\n",
        "resize_to = (160, 160)\n",
        "resize_tf = transforms.Compose([\n",
        "    transforms.Resize(resize_to),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_ds_resized = datasets.ImageFolder(train_dir, transform=resize_tf)\n",
        "\n",
        "loader = DataLoader(train_ds_resized, batch_size=64, shuffle=True, num_workers=0)\n",
        "\n",
        "def estimate_mean_std(dataloader, max_batches=50):\n",
        "    cnt = 0\n",
        "    mean = torch.zeros(3)\n",
        "    sq_mean = torch.zeros(3)\n",
        "    for i, (imgs, _) in enumerate(dataloader):\n",
        "        imgs = imgs.view(imgs.size(0), imgs.size(1), -1)  # (B, C, H*W)\n",
        "        mean += imgs.mean(2).sum(0)\n",
        "        sq_mean += (imgs ** 2).mean(2).sum(0)\n",
        "        cnt += imgs.size(0)\n",
        "        if (i + 1) >= max_batches:\n",
        "            break\n",
        "    mean = mean / cnt\n",
        "    std = (sq_mean / cnt - mean ** 2).sqrt()\n",
        "    return mean, std\n",
        "\n",
        "est_mean, est_std = estimate_mean_std(loader, max_batches=50)\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "axes = axes.flatten()\n",
        "num_show = min(8, len(train_ds_resized))\n",
        "indices = np.random.choice(len(train_ds_resized), size=num_show, replace=False)\n",
        "for ax, idx in zip(axes, indices):\n",
        "    img, label = train_ds_resized[int(idx)]\n",
        "    npimg = img.permute(1, 2, 0).numpy()\n",
        "    ax.imshow(np.clip(npimg, 0, 1))\n",
        "    ax.set_title(train_ds_resized.classes[label])\n",
        "    ax.axis('off')\n",
        "\n",
        "for ax in axes[num_show:]:\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.suptitle(f'Sample training images (resized to {resize_to[0]}x{resize_to[1]})')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "X9wbptrt-LYX",
        "outputId": "fe1156ef-082a-4c91-c55a-5cf18859f32c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10 classes:\n",
            " ['n01440764', 'n02102040', 'n02979186', 'n03000684', 'n03028079', 'n03394916', 'n03417042', 'n03425413', 'n03445777', 'n03888257']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2799196526.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mest_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mest_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimate_mean_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2799196526.py\u001b[0m in \u001b[0;36mestimate_mean_std\u001b[0;34m(dataloader, max_batches)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0msq_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (B, C, H*W)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mmean\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \"\"\"\n\u001b[1;32m    244\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3522\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3524\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3526\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        # === OPTIMIZATION 1: Shared ReLU ===\n",
        "        # Use single ReLU instance instead of creating multiple\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.bn1   = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2   = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion,\n",
        "                               kernel_size=1, bias=False)\n",
        "        self.bn3   = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet50(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(ResNet50, self).__init__()\n",
        "\n",
        "        # === OPTIMIZATION 2: Track inplanes properly ===\n",
        "        self.inplanes = 64\n",
        "\n",
        "        # Initial conv + bn + relu + maxpool\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1   = nn.BatchNorm2d(64)\n",
        "        self.relu  = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Layers / \"stages\" using bottleneck blocks\n",
        "        self.layer1 = self._make_layer(Bottleneck, 64,  3, stride=1)\n",
        "        self.layer2 = self._make_layer(Bottleneck, 128, 4, stride=2)\n",
        "        self.layer3 = self._make_layer(Bottleneck, 256, 6, stride=2)\n",
        "        self.layer4 = self._make_layer(Bottleneck, 512, 3, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * Bottleneck.expansion, num_classes)\n",
        "\n",
        "        # === OPTIMIZATION 3: Improved initialization ===\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        \"\"\"Create one stage of the network with `blocks` blocks.\"\"\"\n",
        "        downsample = None\n",
        "\n",
        "        # If stride != 1 or channel mismatch, need downsample path\n",
        "        if stride != 1 or self.inplanes != out_channels * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, out_channels * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, out_channels, stride, downsample))\n",
        "        self.inplanes = out_channels * block.expansion\n",
        "\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"Optimized weight initialization for faster convergence.\"\"\"\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                # === OPTIMIZATION 4: Better conv initialization ===\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                # === OPTIMIZATION 5: BN initialization ===\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                # === OPTIMIZATION 6: FC layer initialization ===\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # === OPTIMIZATION 7: Zero-initialize final BN in residual blocks ===\n",
        "        # This makes residual branches start as identity functions\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, Bottleneck):\n",
        "                nn.init.constant_(m.bn3.weight, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)  # More explicit than x.flatten(1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZnVUJv8S-NcY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and validation code for imagenette2-160 dataset (verbose logging)\n",
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "\n",
        "# Paths\n",
        "data_dir = '/content/drive/MyDrive/imagenette2-160'\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "val_dir = os.path.join(data_dir, 'val')\n",
        "\n",
        "# Data transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((160, 160)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((160, 160)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Datasets and loaders\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
        "val_dataset = datasets.ImageFolder(val_dir, transform=val_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Model, loss, optimizer\n",
        "num_classes = len(train_dataset.classes)\n",
        "model = ResNet50(num_classes=num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Separate bn/bias params from others for different weight decay\n",
        "bn_params = []\n",
        "other_params = []\n",
        "for name, param in model.named_parameters():\n",
        "    if 'bn' in name or 'bias' in name:\n",
        "        bn_params.append(param)\n",
        "    else:\n",
        "        other_params.append(param)\n",
        "\n",
        "optimizer = torch.optim.SGD([\n",
        "    {'params': other_params, 'weight_decay': 1e-4},\n",
        "    {'params': bn_params, 'weight_decay': 0.0}\n",
        "], lr=0.1, momentum=0.9)\n",
        "\n",
        "# Scheduler: warmup + cosine annealing using LambdaLR\n",
        "warmup_epochs = 5\n",
        "epochs = 30\n",
        "\n",
        "def lr_lambda(epoch):\n",
        "    # returns multiplicative factor for base_lr\n",
        "    if epoch < warmup_epochs:\n",
        "        # Linear warmup from 0 -> 1 over warmup_epochs\n",
        "        return float((epoch + 1) / warmup_epochs)\n",
        "    else:\n",
        "        # Cosine annealing for remaining epochs\n",
        "        progress = float((epoch - warmup_epochs) / max(1, (epochs - warmup_epochs)))\n",
        "        return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def train(model, loader, optimizer, criterion, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # tqdm over loader; set dynamic postfix each batch\n",
        "    with tqdm(enumerate(loader), total=len(loader), desc=f\"EPOCH: {epoch}\", leave=True) as t:\n",
        "        last_loss = 0.0\n",
        "        for batch_idx, (images, labels) in t:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # stats\n",
        "            last_loss = loss.item()\n",
        "            running_loss += last_loss * images.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            acc_pct = 100.0 * correct / total if total > 0 else 0.0\n",
        "\n",
        "            # update progress bar postfix to mimic the format you showed\n",
        "            t.set_postfix_str(f\"Loss={last_loss:.6f} Batch_id={batch_idx} Accuracy={acc_pct:.2f}\")\n",
        "\n",
        "    epoch_loss = running_loss / total if total>0 else 0.0\n",
        "    epoch_acc = 100.0 * correct / total if total>0 else 0.0\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def test(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(loader, desc='Test', leave=True):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() * images.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    avg_loss = test_loss / total if total>0 else 0.0\n",
        "    acc_pct = 100.0 * correct / total if total>0 else 0.0\n",
        "    print(f\"\\nTest set: Average loss: {avg_loss:.4f}, Accuracy: {correct}/{total} ({acc_pct:.2f}%)\\n\")\n",
        "    return avg_loss, acc_pct"
      ],
      "metadata": {
        "id": "AMwglatx-YqU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"EPOCH: {epoch}\")\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device, epoch)\n",
        "    test_loss, test_acc = test(model, val_loader, criterion, device)\n",
        "    # step scheduler\n",
        "    scheduler.step()\n",
        "    current_lr = scheduler.get_last_lr()[0]\n",
        "    print(f\"Epoch summary -> Train loss: {train_loss:.4f}, Train acc: {train_acc:.2f}%, Val loss: {test_loss:.4f}, Val acc: {test_acc:.2f}%, LR: {current_lr:.6f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aohVvhdF-bcl",
        "outputId": "17e11d82-9edd-4b8d-e384-60d502f5da61"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EPOCH: 0: 100%|██████████| 296/296 [00:53<00:00,  5.50it/s, Loss=1.021060 Batch_id=295 Accuracy=68.99]\n",
            "Test: 100%|██████████| 123/123 [00:16<00:00,  7.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.2955, Accuracy: 2429/3925 (61.89%)\n",
            "\n",
            "Epoch summary -> Train loss: 0.9261, Train acc: 68.99%, Val loss: 1.2955, Val acc: 61.89%, LR: 0.099606\n",
            "\n",
            "EPOCH: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "EPOCH: 1: 100%|██████████| 296/296 [00:53<00:00,  5.52it/s, Loss=0.719508 Batch_id=295 Accuracy=74.03]\n",
            "Test: 100%|██████████| 123/123 [00:16<00:00,  7.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.0372, Accuracy: 2587/3925 (65.91%)\n",
            "\n",
            "Epoch summary -> Train loss: 0.8032, Train acc: 74.03%, Val loss: 1.0372, Val acc: 65.91%, LR: 0.098429\n",
            "\n",
            "EPOCH: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "EPOCH: 2: 100%|██████████| 296/296 [00:53<00:00,  5.55it/s, Loss=0.587814 Batch_id=295 Accuracy=76.08]\n",
            "Test: 100%|██████████| 123/123 [00:16<00:00,  7.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.0980, Accuracy: 2696/3925 (68.69%)\n",
            "\n",
            "Epoch summary -> Train loss: 0.7115, Train acc: 76.08%, Val loss: 1.0980, Val acc: 68.69%, LR: 0.096489\n",
            "\n",
            "EPOCH: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "EPOCH: 3: 100%|██████████| 296/296 [00:53<00:00,  5.51it/s, Loss=0.715083 Batch_id=295 Accuracy=79.26]\n",
            "Test: 100%|██████████| 123/123 [00:15<00:00,  7.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.8572, Accuracy: 2846/3925 (72.51%)\n",
            "\n",
            "Epoch summary -> Train loss: 0.6406, Train acc: 79.26%, Val loss: 0.8572, Val acc: 72.51%, LR: 0.093815\n",
            "\n",
            "EPOCH: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "EPOCH: 4: 100%|██████████| 296/296 [00:53<00:00,  5.53it/s, Loss=0.869792 Batch_id=295 Accuracy=80.75]\n",
            "Test: 100%|██████████| 123/123 [00:16<00:00,  7.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.1554, Accuracy: 2685/3925 (68.41%)\n",
            "\n",
            "Epoch summary -> Train loss: 0.5687, Train acc: 80.75%, Val loss: 1.1554, Val acc: 68.41%, LR: 0.090451\n",
            "\n",
            "EPOCH: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "EPOCH: 5: 100%|██████████| 296/296 [00:53<00:00,  5.50it/s, Loss=0.518012 Batch_id=295 Accuracy=83.84]\n",
            "Test: 100%|██████████| 123/123 [00:16<00:00,  7.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.8279, Accuracy: 2945/3925 (75.03%)\n",
            "\n",
            "Epoch summary -> Train loss: 0.4987, Train acc: 83.84%, Val loss: 0.8279, Val acc: 75.03%, LR: 0.086448\n",
            "\n",
            "EPOCH: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "EPOCH: 6: 100%|██████████| 296/296 [00:53<00:00,  5.50it/s, Loss=0.526895 Batch_id=295 Accuracy=86.31]\n",
            "Test: 100%|██████████| 123/123 [00:16<00:00,  7.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.9932, Accuracy: 2882/3925 (73.43%)\n",
            "\n",
            "Epoch summary -> Train loss: 0.4142, Train acc: 86.31%, Val loss: 0.9932, Val acc: 73.43%, LR: 0.081871\n",
            "\n",
            "EPOCH: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "EPOCH: 7: 100%|██████████| 296/296 [00:53<00:00,  5.49it/s, Loss=0.420150 Batch_id=295 Accuracy=88.15]\n",
            "Test: 100%|██████████| 123/123 [00:15<00:00,  7.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.0520, Accuracy: 2804/3925 (71.44%)\n",
            "\n",
            "Epoch summary -> Train loss: 0.3542, Train acc: 88.15%, Val loss: 1.0520, Val acc: 71.44%, LR: 0.076791\n",
            "\n",
            "EPOCH: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "EPOCH: 8: 100%|██████████| 296/296 [00:53<00:00,  5.49it/s, Loss=0.160778 Batch_id=295 Accuracy=90.80]\n",
            "Test: 100%|██████████| 123/123 [00:15<00:00,  7.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.9620, Accuracy: 2928/3925 (74.60%)\n",
            "\n",
            "Epoch summary -> Train loss: 0.2802, Train acc: 90.80%, Val loss: 0.9620, Val acc: 74.60%, LR: 0.071289\n",
            "\n",
            "EPOCH: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "EPOCH: 9: 100%|██████████| 296/296 [00:53<00:00,  5.51it/s, Loss=0.151877 Batch_id=295 Accuracy=92.26]\n",
            "Test: 100%|██████████| 123/123 [00:15<00:00,  7.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.0718, Accuracy: 2857/3925 (72.79%)\n",
            "\n",
            "Epoch summary -> Train loss: 0.2318, Train acc: 92.26%, Val loss: 1.0718, Val acc: 72.79%, LR: 0.065451\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sOraimF7BXnI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}